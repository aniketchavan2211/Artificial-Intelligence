## Agenda

- [History Of AI](#History-Of-AI)
- [What is Artificial Intelligence ?](#What-is-Artificial-Intelligence-?)
- [AI Applications](#AI-Applications)
- [Types of AI](#Types-Of-AI)
- [Programming Languages for AI](#Programming-Languages-For-AI)
- [Machine Learning](#Introduction-to-Machine-Learning)
- [Machine Learning Algorithms](#Types-Of-Machine-Learning)
- [Limitations of Machine Learning](#Limitation-of -Machine-Learning)
- [Deep Learning](#Introduction-of-Deep-Learning)
- [Neural Networks](#Single---Layer-Perceptron)
- [Natural Language Processing](#Natural-Language-Processing-(-NLP-))

## History Of AI

**Greek Mythology - Talos**
Talos was a giant animated bronze warrior programmed to guard the island of Crete created by Hephaestus.

**1950 - Alan Turing**
Alan Turing published a landmark paper in which he speculated about the possibility of creating machines that think.

**1951 - Game AI**
Christoper Strachey wrote a checkers program and Dietrich Prinz wrote one for chess.

**1956 - The Birth of AI**
John McCarthy first coined the term "***Artificial Intelligence***" in 1956 at the Dartmouth Conference.

**1959 - First AI Laboratory**
MIT AI Lab was first set up in 1959. The research on AI began.

**1960 - General Motors Robot**
First robot was introduced to General Motors assembly line.

**1961 - First Chatbot**
The first AI chatbot called ELIZA was introduced in 1961.

**1997 - IBM Deep Blue**
IBM's Deep Blue beats world champion Garry Kasparov in the game of chess.

**2005 - DARPA Grand Challenge**
Standford Racing Team's autonomous robotic car.Stanley wins the 2005 DARPA Grand Challenge.

**2011 - IBM Watson**
IBM's question answering system. Watson defeated the two greatest Jeopardy! champion. Brad Rutter and Ken Jennings.

AI covers Domain like - Machine Learning, Deep Learning, Neural Networks, Natural Language Processing, Knowledge Base,  Expert Systems, Image Processing, Computer Vision and so .

**Demand of AI**

- More Computational Power ( GPU & NPU )
- More Data ( Big Data )
- Better Algorithms ( ML )
- Broad Invest

## What is Artificial Intelligence ?

John McCarthy first coined the term Artificial Intelligence in the year 1956.  
John McCarthy defined Artificial Intelligence as the science and engineering of making intelligent machines.

**What is AI ?**
> The Theory and Development  of computer systems able to performs tasks normally requiring human intelligence, such as visual perception, speech recognition, decision-making and translation between languages.

## AI Applications

- Google Search Engines

Based on users history, locations data, etc, AI model can predicts or guess user search.

- J.P. Morgan COiN

J.P. Morgan Chase's Contract Intelligence ( COiN ) platform uses AI, machine learning and image recognition software to analyze legal documents.

Manually reviewing 12,000 agreements takes over 36,000 hours. AI can do in a seconds.

- IBM Watson AI 

Healthcare organisation use IBM AI ( Watson ) technology for medical diagnosis.

-  Google AI Eye Doctor

Google AI Eye Doctor can examine retina scans and identify a condition called diabetic retinopathy.

- Facebook

Facebook uses Machine Learning & Deep Learning to detect facial features and tag your friends.

- X  ( formally Twitter )

X ( formally Twitter ) is using AI to identify hate speech and terroristic language in tweets.

The company discovered and banned 300, 000 terrorist-linked accounts, 95% of which were found by non-human, artificial intelligent machines.

- Google Duplex ( Virtual Assistant )

The Google Duplex can not only respond to calls and book appointments for you, it adds a human touch

- Tesla ( Self Driving Cars )

"Tesla will have fully self-driving cars ready by the end of the year and a "robo taxi" version - one that can ferry passengers without anyone behind the wheel - ready for the streets next year."

- Netflix

Over 75% of what you watch is recommended by Netflix. Recommendations are made by machine learning.

-  Gmail Spam Filtering

AI use to Filter out Spam and Authentic / Legit Email.

## Types Of AI

-  Artificial `Narrow` Intelligence
Artificial Narrow Intelligence ( ANI ) also known as weak AI involves applying AI only to specific tasks.

Examples : Alexa

- Artificial `General` Intelligence
Artificial General Intelligence ( AGI )  also known as strong AI, involves machines that possess the ability to performs any intellectual task that a human being can.

Example:  Alpha Go

- Artificial `Super` Intelligence
Artificial Super Intelligence ( ASI ) is a term referring to the time when the capability of computer will surpass humans.

Example: Not Exist yet ...

## Programming Languages For AI

- Python
- R language
- Java
- Lisp 
- Prolog
- C++

### Introduction to Python

- Python is an interpreted, object-oriented, high-level programming language with dynamic semantics.
- Python was created by Guido Rossum in 1989 and is very easy to learn.

- Simple and Easy to Learn - Python is a simple and easy to learn, read & write
- Free and Open Source - Python is an example of a FLOSS (Free/Libre and Open Source Software) which means one can freely distribute copies of this software, reads it's source code, modify it, etc.
- High-Level Language - One does not need to bother about the low-level details like memory allocations, etc. while writing Python script.
- Portable - Supported by many platforms like Linux, Windows, FreeBSD, Macintosh, Solaris, OS/2, Amiga, AROS, AS/400, BeOS, OS/390, PlayStation, Windows CE, etc.
- Supports different Programming Paradigm - Python supports procedure-oriented programming as well as object-oriented programming.
- Extensible - Python code can invoke C and C++ libraries, can be called from and C++ programs, can integrate with Java and .NET components.

## Introduction to Machine Learning

Machine Learning is subset of AI, AI learned pattern from ML from given dataset, it draws a pattern from it.

## Need for Machine Learning

"***"Over 2.5 quintillion bytes of data are created every single day, and it's only going to grow from there. By 2020, it's estimated that 1.7 MB of data will be created every seconds for every person on earth."***

- Cloud Data
- Internet Of Things
- Social Media

- Increase in Data Generation
- Improve Decision Making
- Uncovers patterns & trends in data
- Solve Complex Problems

## What is Machine Learning ?

Arthur Samuel first coined the term Machine Learning in the year 1959.

**What is Machine Learning**
>"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E."

A simpler definition of Machine Learning
Machine learning is a subset of Artificial Intelligence ( AI ), which provides machines the ability to learn automatically & improve from experience without being explicitly  programmed.

Feed Data -> Training the Machine ->  Build a Model ->  Predicting Outcome

## Machine Learning Definitions

**Algorithm:** A set of rules and statistical techniques used to learn pattern from data.

**Model:** A model is trained by using a Machine Learning Algorithm.

**Predictor Variable:** It is a feature(s) of the data that can be used to predict the output.

**Response Variable:** It is a the feature or the output variable ( target variable ) that needs to be predicted by using the predictor variable(s).

**Training Data:** The Machine Learning model is built using the training data.

**Testing Data:** The Machine Learning model is evaluated using the testing data.

## Machine Learning Process

Steps to follow:
- Define Objectives 
- Data Gathering
- Preparing Data
- Data Exploration
- Building a Model
- Model Evaluation
- Predictions

**Machine Learning Process**
> The Machine Learning process involves building a **Predictive model** that can be used to find a **solution** for **Problem Statement**.

**Step 1: Define the objective of the Problem**
> To predict the possibility of rain by studying the weather conditions.

- What are we trying to predict? -> ( Continuous variable or Discrete variable )
- What are the target features? 
- What is the input data?
- What kind of problems we are facing? Binary classification ? Clustering ? Regression Problem ?

**Step 2: Data Gathering**
> Data such as weather conditions, humidity level, temperature, pressure, etc are either collected manually or scarped from web.

**Step 3: Preparing Data
> Data Cleaning involves getting rid of inconsistencies in data such as missing values or redundant variables.

- Transforms data into desired format
- Data Cleaning
	- Missing values
	- Corrupted data
	- Remove unnecessary data

**Step 4: Exploratory Data Analysis**
> Data Exploration involves understanding the patterns and trends in the data. At this stage all the useful insights are drawn and correlations between the variables are understood.

**Step 5: Building a Machine Learning Model**
>At this stage a Predictive Model is built by using Machine Learning Algorithms such as Linear Regression, Decision Trees, etc.

Split data into two parts: training  data (80%) & testing data. (20%).

- Machine Learning model is built by using the training data set.
- The model is the Machine Learning algorithms that predicts the output by using the data fed to it.

**Step 6: Model Evaluation & Optimization**
>The efficiency of the model is evaluated and any further improvement in the model are implemented.

- Machine Learning model is evaluated by using the testing data set.
- The accuracy of the model is calculated.
- Further improvement in the model are done by using techniques like Parameter tuning.

**Step 7: Predictions**
> The final outcome is predicted after performing parameter tuning and improving the accuracy of the model.

## Types Of Machine Learning 

- Supervised Learning 
- Unsupervised Learning
- Reinforcement Learning

### Supervised Learning 

Supervised learning is a technique in which we teach or train the machine using data which is well labelled.

Labelled data -> ML Algorithms -> classes of labelled data

You have well labelled dataset, take an example Tom & Jerry, You feed Tom and Jerry how they looks and basis on that Algorithm will classify or separate them forming class of Tom contains tom data and class jerry contains jerry data.
### Unsupervised Learning

Unsupervised learning is the training of machine using information that is unlabelled and allowing the algorithms to act on that information without guidance.

Unlabelled data -> ML  Algorithms -> Clusters formed on features

Take previous example of Tom & Jerry, In Unsupervised learning data is unlabelled, on building model, model will identify features as of Big Ears, skins etc, on basis of that data, it output as grouping the type a and type b , clustering basis on features on type a and type b,  Compare appearance both of them - Tom & Jerry.

### Reinforcement Learning

Reinforcement Learning is a part of Machine learning where an agent is put in an environment and he learns to behave in this environment by performing certain actions and observing the rewards which it gets from those actions.

In Reinforcement Learning , we don't give data, we put Agent AI, in a environment, and Agent AI had to explore, without knowing anything of it's environment, on basis of actions it gets rewards or  punishment, AI learn will learn which things to do and not to do.

### Difference  

|                    | Supervised Learning                                                      | Unsupervised Learning                                           | Reinforcement Learning                                                                      |
| ------------------ | ------------------------------------------------------------------------ | --------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| Definition         | The machine learns by using labelled data.                               | The machine is trained on unlabelled data without any guidance. | An agent interacts with its environment by producing actions & discovers errors or rewards. |
| Types of Problems  | Regression & Classification                                              | Association & Clustering                                        | Reward based                                                                                |
| Types of data      | Labelled data                                                            | Unlabelled data                                                 | No pre-defined data                                                                         |
| Training           | External supervision                                                     | No supervision                                                  | No supervision                                                                              |
| Approch            | Map labelled input to known output                                       | Understand patterns and discovers output                        | Follow trail and error method                                                               |
| Popular Algorithms | Linear regression, Logistic regression, Support Vector Machine, KNN, etc | K-means, C-means, etc                                           | Q-learning, SARSA, etc                                                                      |

## Types of Problems Solved Using Machine Learning

**Regression vs Classification vs Clustering**

| Regression                         | Classification                                  | Clustering                                               |
| ---------------------------------- | ----------------------------------------------- | -------------------------------------------------------- |
| Supervised Learning                | Supervised Learning                             | Unsupervised Learning                                    |
| Output is continuous quantity      | Output a categorical quantity                   | Assigns data points into clusters                        |
| Main aim is to forecast or predict | Main aim is to compute the category of the data | Main aim is to group similar items clusters              |
| Eg. Predict  stock market price    | Eg. Classify emails as spam or non-spam         | Eg. Find all transactions which are fraudulent in nature |
| Algorithm: Linear Regression       | Algorithm: Logistic Regression                  | Algorithm: K-means                                       |

**Problem Statement**: To study the House Sales dataset and build a Machine Learning model that  predicts the house pricing index. : 
> Linear Regression Algorithm to predict the house pricing index. 


**Problem Statement**: Study a bank credit dataset and make a decision about whether to approve the loan of an applicant based on profile. :
> KNN Algorithm - Approve Loan OR  Reject Loan

**Problem Statement**: To cluster a set of movies as either good or average based on their social media out reach. :
> K-means Algorithm - Popular Movies OR Non-popular Movies

### Supervised Learning Algorithms

- Linear Regression
- Logistic Regression
- Decision Tree
- Random Forest
- Naive Bayes Classifier
- K-Nearest Neighbour
- Support Vector Machines

#### Linear Regression 

![linear-regression-graph](assets/images/linear-regression-graph.png)

Linear Regression is a method to predict dependent variable (Y) based on values of independent variables (X). It can be used for the cases where we want to predict some continuous quantity.

- Dependent variable (Y):
>  The response variable who's value needs to be predicted.

- Independent variable (X):
> The predictor variable used to predict the response variable.


The following equation is used to represent a linear regression model:

![](assets/images/linear-regression-equation.png)

1. Dependent variable
2. Y intercept
3. Slope
4. Independent variable
5. Error

![](assets/images/linear-regression-graph-w-eqn.png)

#### Logistic Regression

![logistic-regression-graph](assets/images/logistic-regression-graph.png)

Logistic Regression is a method used to predict a dependent variable, given a set of independent variables, such that the dependent variable is categorical.

![logistic-regression-graph-with-equation](assets/images/logistic-regression-graph-w-eqn.png)

![Sigmoid Function](assets/images/sigmoid-function.png)

#### Decision Tree

A Decision Tree is a Supervised Machine Learning algorithm which looks like an inverted tree, wherein each node represents a **predictor variable** (feature), link between the nodes represents a **Decision** and each leaf node represents an **outcome** (response variable).

![Decision Tree Example](assets/images/decision-tree-example.png)

**Root Node**: 
> The root node is the starting point of a tree. At this point, the first split is performed.

**Internal Node**:
> Each internal node represents a decision point (predictor variable) that eventually leads to the prediction of the outcome.

**Leaf / Terminal Node**:
> Leaf nodes represents the final class of the outcome and therefore they're also called terminating nodes.

**Branches**:
> Branches are connection between nodes, they're represented as arrows. Each branch represents a response such as yes or no.


**Steps to Follows:**

**Step 1**: Select ***Best Attributes ( A )***

**Step 2**: Assign A as decision variable for the root node.

**Step 3**: For each value of A, build a descendant of the node.

**Step 4**: Assign classification labels to the leaf node.

**Step 5**: If data is correctly classified: Stop.

**Step 6**: Else: Iterate over the tree.

**Information Gain & Entropy**

**Problem Statement**: To study the data set and create a Decision Tree that classifies the speed of a car as either slow or fast.

| Road type | Obstruction | Speed Limit | Speed |
| --------- | ----------- | ----------- | ----- |
| steep     | yes         | yes         | slow  |
| steep     | no          | yes         | slow  |
| flat      | yes         | no          | fast  |
| steep     | no          | no          | fast  |

**Step 1**:  Select Best Attributes (A)

Q. How do you know which variable best separates the data?
Ans. : The variable with the highest information Gain best divides the data into the desired output classes.

Calculate the following measures:
1. Entropy
2. Information Gain ( IG )

**Entropy**: Entropy measures the impurity or uncertainty present in the data.

**Information Gain**: IG indicates how much "information" a particular feature / variable gives us about the final outcome.

**Calculating IG of parent node ( Speed of Car )**

Find out the fraction of the two classess (slow or fast) present in the parent node:
- P(slow) -> fraction of  'slow' outcomes in the parent node
- P(fast) -> fraction of 'fast' outcomes in the parent node

The formula of calculate P(slow) is:
**P(slow) = no. of 'slow' outcomes in the parent node / total number of outcomes**

P(slow) = 2/4 = 0.5

Similarly for P(fast),

**P(fast) = no. of 'fast' outcomes in the parent node / total number of outcomes**

P(fast) = 2/4 = 0.5

Therefore, the entropy of the parent node is:
**Entropy(parent) = ...**
Entropy(parent) = 1


Calculating IG of child node (Road Type)

Entropy of right side child node(fast)
Entropy of left side child node (slow, slow , fast)

P(slow) = 2/3 = 0.667
P(fast) = 1/3 = 0.334

Therefore, the entropy is:
Entropy(left child node) = {(0.667 log2(0.667)) + 0.334 log2(0.334)} = -{-0.38+(-0.52))} = 0.9

calculate the Entropy (children) with weighted average:
- Total number of outcomes in parent node: 4
- Total number of outcomes in left child node: 3
- Total number of outcomes in right child node: 1

> \[Weighted avg]Entropy(children) = (no. of outcomes in left child node) / (total no. of outcomes in parent node) + (entropy of left node) + (no. of outcomes in right child node) / (total no. of outcomes in parent node) * (entropy of right node)

Entropy(children) with weighted avg. is 0.675

**`Information Gain = entropy(parent) - [weighted average] * entropy(children)`**

Therefore, 
Information Gain(Road type) = 1 - 0.675 = 0.325

So by using the above methodology, you must get the following values for each predictor variable:
- Information Gain (Road type) = 1 - 0.675 = 0.325
- Information Gain (Obstruction) = 1 - 1 = 0
- Information Gain (Speed limit) = 1 - 0 = 1 

#### Random Forest 

![Random Forest](assets/images/random-forest.png)

Random Forest builds multiple decision trees (called the forest) and glues them together to get a more accurate and stable prediction.

Why Random Forest ?
- More Accuracy
- Avoid Overfitting
- Bagging

We're going to use this data set to create a Random Forest that predicts if a person has heart disease or not.


| Blood Flow | Blocked Arteries | Chest Pain | Weight | Heart Disease |
| ---------- | ---------------- | ---------- | ------ | ------------- |
| Abnormal   | No               | No         | 130    | No            |
| Normal     | Yes              | Yes        | 195    | Yes           |
| Normal     | No               | Yes        | 218    | No            |
| Abnormal   | Yes              | Yes        | 180    | Yes           |

**Step 1**: Create a Bootstrapped Data Set
Bootstrapping is an estimation method used to make prediction on a data set by re-sampling it.

| Blood Flow | Blocked Arteries | Chest Pain | Weight | Heart Disease |
| ---------- | ---------------- | ---------- | ------ | ------------- |
| Abnormal   | Yes              | Yes        | 195    | Yes           |
| Abnormal   | No               | No         | 130    | No            |
| Abnormal   | Yes              | Yes        | 180    | Yes           |
| Abnormal   | Yes              | Yes        | 180    | Yes           |

**Step 2**: Creating Decision Trees

- Build a Decision Tree by using the bootstrapped data set
- Begin at the root node & choose the best attribute to split the data set
- Repeat the same process for each of the upcoming branch nodes

**Step 3**: Go back to Step 1 and Repeat

- Each Decision Tree predicts the output class based on the respective predictor variables used in that tree.
- Go back to step 1, create a new bootstrapped data set and then build a Decision Tree by considering only a subset of variables at each step.
- This iteration is performed 100's of times, creating multiple decision trees.

**Step 4**: Predicting the outcome of a new data point

- To predict whether a new patient has heart disease or not, run the new data down the decision trees
- After running the data down all the trees in the Random Forest, we check which glass got the majority votes.
- In our case, the class 'Yes' received the most number of votes, hence it's clear that the new patient has heart disease.

**Step 5**: Evaluate the Model

- In a real-world problem, about 1/3rd of the original data set is not included in the bootstrapped data set.
- This sample data set that does not include in the bootstrapped data set is known as the Out-Of-Bag (OOB) data set.
- we can measure the accuracy of a Random Forest by the proportion of OOB samples that are correctly classified.
- 
#### Naive Bayes

- Naive Bayes is based on the Bayes Theorem that is used to solve classification problems by following a probabilistic approach.
- It is based on the idea that the predictor variables in a Machine Learning model are independent of each other.

![Naive Bayes Equation](assets/images/naive-bayes-equation.png)

- P( A|B ): Conditional probability of event A occurring, given the event B
- P( A ): Probability of event A occurring
- P( B ): Probability of event B occurring
- P( B|A ): Conditional probability of event B occurring, given the event A


![Naive Bayes Example](assets/images/naive-bayes-example.png)


To predict whether the animal is a Cat, Parrot or a Turtle based on the defined predictor variables (swim, wings, green , sharp teeth).

|             | Swim | Wings | Green | Sharp Teeth |
| ----------- | ---- | ----- | ----- | ----------- |
| Observation | True | False | True  | False       |

To solve this, we will use the Naive Bayes Approach:

![Naive Bayes Approach](assets/images/naive-bayes-approach.png)

In the observation, the variables Swim and Green are true and the outcome can be any one of the animals (Cats, Parrots, Turtles).

![Naive Bayes Approach](assets/images/naive-bayes-approach.png)

**To check if the animals is a cat**:
> P( Cat | Swim, Green) = P( Swim|Cat ) * P( Green|Cat ) * P( Cat ) / P(  Swim, Green )
> = 0.9 * 0 * 0.333 / P( Swim, Green ) 
> = 0

**To check if the animals is a parrot**:
> P( Parrot | Swim, Green) = P( Swim|Parrot ) * P( Green|Parrot ) * P( Parrot ) / P(  Swim, Green )
> = 0.1 * 0.80 * 0.333 / P( Swim, Green ) 
> = 0.0264 / P( Swim, Green )

**To check if the animals is a Turtle**
> P( Turtle | Swim, Green) = P( Swim|Turtle ) * P( Green|Turtle ) * P( Turtle ) / P(  Swim, Green ) 
> = 1 * 0.2 * 0.333 / P( Swim, Green ) 
> = 0.0666 / P( Swim, Green )


#### K Nearest Neighbour ( KNN )

K Nearest Neighbour is a Supervised Learning Algorithm that classifies a new data point into the target class, depending on the features of it's neighbouring data points

![KNN-Algorithm #01](assets/images/knn-algorithm-01.png)


![KNN Algorithm #02](assets/images/knn-algorithm-02.png)


**Problem Statement**: Assign the new data point into one of the two clusters

![KNN Algorithm #03](assets/images/knn-algorithm-03.png)


Choose the value of 'k', here k=3 and find the 3 nearest neighbours

![KNN Algorithm #04](assets/images/knn-algorithm-04.png)

=> Class A or Square 

Here k= 7, find the nearest neighbours

![KNN Algorithm #05](assets/images/knn-algorithm-05.png)

##### Euclidean Distance

![KNN Algorithm #06](assets/images/knn-algorithm-06.png)

#### Support Vector Machine ( SVM )

Support Vector Machine ( SVM ) is a supervised classification  method that separates data using hyperplanes.

- Supervised machine learning algorithm
- Classification & Regression algorithm
- SVM kernel functions

![KNN Algorithm #07](assets/images/knn-algorithm-07.png)


![KNN Algorithm #08](assets/images/knn-algorithm-08.png)

![KNN Algorithm #09](assets/images/knn-algorithm-09.png)


![KNN Algorithm #10](assets/images/knn-algorithm-10.png)


![KNN Algorithm #11](assets/images/knn-algorithm-11.png)



![KNN Algorithm #12](assets/images/knn-algorithm-12.png)

### Unsupervised Learning Algorithms

#### K-Means Clustering

The process by which object are classified into a predefined number of groups in that so that they  are as much dissimilar as possible from one group to another group, but as much similar as possible within each group.

![K-Means Clustering  Flowchart](assets/images/k-means-clustering-flowchart.png)

![K-Means Clustering Steps](assets/images/k-means-clustering-steps.png)

**The Elbow Method**:
> First of all, compute the sum of squared error (SSE) for some values of *k* (for example 2, 4, 6, 8, etc.). The SSE is defined as the sum of the squared distance between each member of the cluster and its centroid. Mathematically:

![K-Means Clustering Elbow Method](assets/images/k-means-clustering-elbow-method.png)

### Reinforcement Learning 

#### **Reinforcement Learning Analogy**

Scenario 1: Baby starts crawling and makes it to the candy

![Reinforcement Learning Baby](assets/images/reinforcement-learning-baby.png)


Reinforcement Learning System is comprised of two main components:
- Agent
- Environment

![Reinforcement Learning Agent Environment](assets/images/reinforcement-learning-agent-env.png)


#### **Reinforcement Learning Example**

**Counter Strike**

![Reinforcement Learning Counter Strike Example](assets/images/reinforcement-learning-counter-strike-example.png)

#### **Reinforcement Learning Terminologies**

**Basic Terminologies in Reinforcement Learning

![RL Terminologies #01](assets/images/reinforcement-learning-terminologies-01.png)

![RL Terminologies](assets/images/reinforcement-learning-terminologies-02.png)

#### **Reinforcement Learning Concepts**

**Reward Maximization**

Reward maximization theory states that, a RL agent must be trained in such a way that, he takes the best action so that the reward is maximum.

![Reward Maximization](assets/images/reinforcement-learning-reward-maximization.png)

**Exploration & Exploitation**

**Exploitation**: is about using the already known exploited information to heighten the rewards.

**Exploration**: is about exploring and capturing more information about an environment.

**Markov's Decision Process**
> The mathematical approach for mapping a solution in reinforcement learning is called Markov Decision Process (MDP).

![Markov's Decision Process](assets/images/reinforcement-learning-markov-decision-process.png)

The following parameters are used to attain a solution:
- Set of actions, A
- Set of states, S
- Reward, R
- Policy, 
- Value, V

![Markov Decision Process](assets/images/reinforcement-learning-markov-decision-process-02.png)

### Understanding Q-Learning  


![Q-Learning ](assets/images/q-learning.png)


![Q-Learning #01](assets/images/q-learning-01.png)

![Q-Learning #02](assets/images/q-learning-02.png)

![Q-Learning #03](assets/images/q-learning-03.png)

![Q-Learning #04](assets/images/q-learning-04.png)

![Q-Learning #05](assets/images/q-learning-05.png)

![Q-Learning #06](assets/images/q-learning-06.png)

![Q-Learning #07](assets/images/q-learning-07.png)

![Q-Learning #08](assets/images/q-learning-08.png)

![Q-Learning #09](assets/images/q-learning-09.png)

## AI vs ML vs DL

**Artificial Intelligence** : A technique which enables machines to mimic human behaviour.

**Machine Learning** : Subset of AI technique which use statistical methods to enable machines to improve with experience.

**Deep Learning** : Subset of Machine Learning which make the computation of multi-layer neural network feasible.

## Limitation of Machine Learning

- High Dimensional Data
- Image Recognition

One of the big challenge with traditional Machine Learning models is a process called feature extraction. For complex problem such as object recognition or handwriting recognition, this is a huge challenge.

## Introduction of Deep Learning

**Why Deep Learning ?**
> Deep Learning models are capable to focus on the right feature by themselves, requiring little guidance from the programmer. These models also partially solve the dimensionality problem.

![Deep Learning #01](assets/images/deep-learning-01.png)

The idea behind Deep Learning is to build learning algorithms that mimic Human Brain.

**How Deep Learning Work ?**

Deep Learning is a form of machine learning that uses a model of computing that's very much inspired by the structure of the brain, so lets understand that first.

![Biological Neuron](assets/images/deep-learning-biological-neuron-02.png)

**Biological Neuron

Deep Learning is a collection of statistical machine learning techniques used to learn feature hierarchies based on the concept of artificial neural networks.

![Deep Learning #03](assets/images/deep-learning-03.png)

**Image Recognition using Deep Learning**

1. Pass the high dimensional data to the input layer.
2. Output received from the input layer contains patterns which are extracted.
3. Output will be fed to the Hidden Layer 1.
4. Hidden Layer 2 will able to form the entire faces.
5. The output layer performs classification.

### Single - Layer Perceptron

**A Perceptron** : An Artificial Neuron or a Perceptron is a linear model used for binary classification. It models a neuron which has a set of inputs, each of which is given a specific weight. The neuron computes some function on these weighted inputs and gives the output.

![Perceptron](assets/images/deep-learning-perceptron-04.png)

**Perceptron or Artificial Neuron**

**Perceptron Learning Analogy**

Suppose you want to go to a party happening near you house. And your decision depends on multiple factors:

1. How is the weather ?
2. Your wife is going with you ?
3. Any public transport is available ? 

![Perceptron Learning Analogy](assets/images/deep-learning-05.png)


![Deep Learning #06](assets/images/deep-learning-06.png)

*`1` means going to party & `0` means staying at home.*

Suppose for you the most important factor is weather.
Weather -> Good = Party
Weather -> Not Good = Sit at Home

![Deep Learning #07](assets/images/deep-learning-07.png)


![Deep Learning #08](assets/images/deep-learning-08.png)

### Limitations of a Perceptron
**Dealing with non-linearly separable data** :

![Deep Learning #09](assets/images/deep-learning-09.png)

> A Multilayer Perceptron with backpropagation can be used to solve this problem.

### Multi-layer Perceptron - Artificial Neural Network

**Multi-layer  Perceptron**
> A Multi-layer Perceptron has the same structure of a single layer perceptron but with one or more hidden layers and is thus considered a deep neural network. 

![Multi-layer Perceptron](assets/images/deep-learning-10.png)

- The weights between the units are the primary means of long-term information storage in neural networks.
- Updating the weights is the primary way the neural network learns new information.

![Deep Learning  #11](assets/images/deep-learning-11.png)

A set of inputs are passed to the first hidden layer, the activations from that layer are passed to the next layer and so on, until you reach the output layer.

The Backpropagation algorithm is a supervised learning method for Multilayer Perceptron.

![backpropagation](assets/images/deep-learning-12.png)

Maximum weight is assigned to the most important lead/input.

### Training a Neural Network

The most common deep learning algorithm for supervised training of the multi-layer perceptrons is known as *backpropagation*. After calculating the weighted sum of inputs and passing them through the activation function we propagate backwards and update the weights to reduce the error ( desired output - model output ). Consider the below example.

| Input | Desired Output |
| ----- | -------------- |
| 0     | 0              |
| 1     | 1              |
| 2     | 4              |

 Let's consider the initial value of the weight as 3 and see the model output:
 
| Input | Desired Output | Model Output |
| ----- | -------------- | ------------ |
| 0     | 0              | 0            |
| 1     | 2              | 3            |
| 2     | 4              | 6            |

Now, we will see the error ( Absolute and Square )

| Input | Desired Output | Model Output (W=3) | Absolute Error | Square Error |
| ----- | -------------- | ------------------ | -------------- | ------------ |
| 0     | 0              | 0                  | 0              | 0            |
| 1     | 2              | 3                  | 1              | 1            |
| 2     | 4              | 6                  | 2              | 4            |

 
Let's update the weight value and make it as 4


| Input | Desired Output | Model Output (W=3) | Absolute Error | Square Error | *Model Output (W=4)* |
| ----- | -------------- | ------------------ | -------------- | ------------ | ------------------ |
| 0     | 0              | 0                  | 0              | 0            | *0*                  |
| 1     | 2              | 3                  | 1              | 1            | *4*                  |
| 2     | 4              | 6                  | 2              | 4            | *8*                  |
Model Output (W=4) = Input x W(eight)

Notice that the error has increased

| Input | Desired Output | Model Output(W=3) | Absolute Error | Square Error | *Model Output (W=4)* | *Square Error* |
| ----- | -------------- | ----------------- | -------------- | ------------ | -------------------- | -------------- |
| 0     | 0              | 0                 | 0              | 0            | *0*                  | *0*            |
| 1     | 2              | 3                 | 1              | 1            | *4*                  | *4*            |
| 2     | 4              | 6                 | 2              | 4            | *8*                  | *16*           |

Relationship between the assigned weight and the error

![Neural Network](assets/images/neural-network-01.png)

**Reducing the Error / Loss**

**Step 1: Calculate the error

![Neural Network #02](assets/images/neural-network-02.png)

**Step 2: Calculate the rate of change of error w.r.t. change in the weights

![Neural Network #03](assets/images/neural-network-03.png)

**Step 3: Based on change in weight, update the weight value.

![Neural Network #04](assets/images/neural-network-04.png)


#### Limitations of Feed Forward Network

A trained feed forward network can be exposed to any random collection of photographs, and the first photograph it is exposed to will not necessarily alter how it classifies the second one.

![Neural Network #05](assets/images/neural-network-05.png)

When you read a book, you understand it based on your understanding of previous words.

![Neural Network #06](assets/images/neural-network-06.png)

Solution : Neural Network that can learned from previous mistakes.

![Neural Network #07](assets/images/neural-network-07.png)

#### Recurrent Neural Network

Recurrent Networks are a type of artificial neural network designed to recognise patterns in sequences of data, such as text, genomes, handwriting, the spoken word, or numerical times series data emanating from sensors, stock markets and government agencies.

Example of Gym :

![Neural Network #08](assets/images/neural-network-08.png)

using Recurrent Network:

![Neural Network #09](assets/images/neural-network-09.png)

![Neural Network #10](assets/images/neural-network-10.png)

![Neural Network #11](assets/images/neural-network-11.png)

#### Convolutional Neural Network ( CNN )

**Why we need CNN ?**

![Neural Network #12](assets/images/neural-network-12.png)

![Neural Network #13](assets/images/neural-network-13.png)

**Convolutional Neural Network**
> In case of CNN the neuron in a layer will only be connected to a small region of the layer before it, instead of all of the neurons in a fully-connected manner.

![Neural Network #14](assets/images/neural-network-14.png)

## Natural Language Processing ( NLP )

**Need for Text Mining & NLP**

- Instagram : 1,736,111 pictures
- X ( Twitter ) : 347,222 Tweets
- Email : 204,000,000 emails
- Facebook : 4,166,667 likes & 200,000 photos

**What is Text Mining ?**
> Text Mining / Text Analytics is the process of deriving meaningful information from natural language text.

Text Mining is process of deriving high quality information from the text. The overall goal is, to turn text into data for analysis, via application of Natural Language Processing ( NLP ).

**What is NLP ?**
>**Natural Language Processing** is a part of computer science and artificial intelligence which deals with human languages.

**Applications of NLP**
- Auto-completion
- Spam Detection
- Predictive typing
- Spell checker
- Sentimental Analysis
- Chatbot
- Speech Recognition
- Machine Translation
- Information Extraction
- Keyword Search
- Advertisement Matching

**Terminologies in NLP**

***Tokenization*** : The process of splitting the whole data ( corpus ) into smaller chunks is known as tokenization.

1. Break a complex sentence into words
2. Understand the importance of each of the words with respect to the sentence
3. Produce a structural description on an input sentence

****Stemming*** : Normalise words into its base form or root form

![NLP Stemming](assets/images/stemming.png)

***Lemmitization***
1. Groups together different inflected forms of a word, called lemma
2. Somehow similar to Stemming, as it maps several words into one common root
3. Output of Lemmatisation is a proper word
4. For example, a Lemmatiser should map *gone*, *going* and *went* into **go**

***Stop Words*** : unnecessary words, how, to, various, know, etc. 

***Document Term Matrix*** 

![Document Term Matrix](assets/images/document-term-matrix.png)



## Reference

- [Artificial Intelligence Full Course | By Edureka!](https://www.youtube.com/watch?v=JMUxmLyrhSk)